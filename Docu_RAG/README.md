# DocuRAG â€“ Retrievalâ€‘Augmented Generation for Document Automation

DocuRAG is a **productionâ€‘oriented RAG pipeline** featuring:
- **Azure AI Search** for hybrid retrieval (BM25 + vector)
- **Azure OpenAI (GPT-4 / o-series)** for grounded, citationâ€‘backed answers
- **FastAPI** backend with async endpoints
- **Agentâ€‘based workflows** (LangChain) for multiâ€‘step reasoning
- **Evaluation metrics** (BLEU, ROUGE, Recall@K, latency)

> **Note:** This repo includes fully wired code with clear extension points. You must set valid Azure resources and environment variables to run endâ€‘toâ€‘end.

## Features
- ğŸ“„ Document ingestion (PDF/DOCX/TXT) â†’ chunking â†’ embedding â†’ Azure AI Search indexing
- ğŸ” Hybrid retrieval (keyword + vector) with optional reranking
- ğŸ¤– Agent workflows to plan/search/summarize with tool access
- ğŸ“Š Evaluation: BLEU, ROUGE, Recall@K, latency + token/cost tracking
- ğŸ³ Dockerfile for containerized deployment; works with Azure App Service

## Quickstart

1) **Clone & install**
```bash
git clone https://github.com/<YOUR-USERNAME>/DocuRAG.git
cd DocuRAG
pip install -r requirements.txt
```

2) **Export environment variables**
```bash
export AZURE_SEARCH_ENDPOINT="https://<your-search>.search.windows.net"
export AZURE_SEARCH_KEY="<your-search-admin-key>"
export AZURE_SEARCH_INDEX="docurag-index"

export AZURE_OPENAI_ENDPOINT="https://<your-aoai>.openai.azure.com/"
export AZURE_OPENAI_KEY="<your-aoai-key>"
export AZURE_OPENAI_DEPLOYMENT="gpt-4o-mini"   # or gpt-4o, gpt-35-turbo etc.

# Optional: caching & telemetry
export REDIS_URL="redis://localhost:6379/0"
export DOCURAG_ENABLE_RERANK="true"
```

3) **Run API**
```bash
uvicorn app.main:app --reload
# Open docs: http://127.0.0.1:8000/docs
```

## Endpoints
- `POST /ingest`  â€“ Upload and index documents (`multipart/form-data` file)
- `POST /chat`    â€“ Ask grounded questions: `{ "query": "...", "top_k": 5 }`
- `GET  /evaluate`â€“ Run sample evaluation suite (BLEU/ROUGE/Recall@K)

## Project Structure
```
DocuRAG/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ main.py          # FastAPI entry; routes
â”‚   â”œâ”€â”€ config.py        # Env config + settings
â”‚   â”œâ”€â”€ ingestion.py     # Load â†’ chunk â†’ embed â†’ index
â”‚   â”œâ”€â”€ retrieval.py     # Hybrid search + rerank + prompts
â”‚   â”œâ”€â”€ agents.py        # LangChain agent orchestration
â”‚   â”œâ”€â”€ evaluation.py    # Metrics (BLEU/ROUGE/Recall@K/latency)
â”‚   â”œâ”€â”€ utils.py         # Helpers (chunking, timing, cost)
â”‚â”€â”€ data/                # Sample docs
â”‚â”€â”€ tests/               # Smoke tests
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ .gitignore
â”‚â”€â”€ README.md
```

## Minimal Local Test (No Azure)
You can smokeâ€‘test the server locally without Azure by calling `/health` and using the stubbed retrieval path (it returns sample chunks).

## Production Notes
- Use **Managed Identity** in Azure instead of raw keys where possible.
- For retrieval optimization, consider **scoring profiles** or reranking; you can also plug in a rerank model.
- Add **telemetry**: latency, token usage, cache hit rate.
- Scale via **Azure App Service** or **Azure Functions** (HTTP trigger pointing to `app.main:app`).

